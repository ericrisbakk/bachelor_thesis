{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import math\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "dataFolder = \"D:\\\\Uni\\\\DataOutput\\\\\"\n",
    "fName_2MIN = \"TerminusEst_MCTS_2MIN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_space_from_column_names(df):\n",
    "    for col in df.columns:\n",
    "        if (col[0] == \" \"):\n",
    "            df = df.rename(columns={col: col[1:]})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering the data from the quick run file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataFolder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4d02190b36f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mqRunFiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml_post\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mqRunFiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataFolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfName_2MIN\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdataQR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqRunFiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataFolder' is not defined"
     ]
    }
   ],
   "source": [
    "l_post = []\n",
    "for i in (range(1, 50, 10)):\n",
    "    l_post.append((i, i+9))\n",
    "\n",
    "qRunFiles = []\n",
    "for post in l_post:\n",
    "    qRunFiles.append(dataFolder + fName_2MIN + \"_\" + str(post[0]) + \"_\" + str(post[1]) + \".csv\")\n",
    "\n",
    "dataQR = pd.read_csv(qRunFiles[0])\n",
    "\n",
    "for d in range (1, 5):\n",
    "    dataQR = pd.concat([dataQR, pd.read_csv(qRunFiles[d])], axis=0)\n",
    "\n",
    "# Appears to be some error in column naming where a single space is in front...\n",
    "\n",
    "\n",
    "for col in dataQR.columns:\n",
    "    if (col[0] == \" \"):\n",
    "        dataQR = dataQR.rename(columns={col: col[1:]})\n",
    "\n",
    "time_searched = dataQR.TIME_TOTAL - dataQR.TIME_BUILD_SEARCH_TREE\n",
    "dataQR.insert(3, \"TIME_SEARCH\", time_searched, True)\n",
    "dataQR = dataQR.sort_values(by=['ID']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Quick look at the data.\n",
    "dataQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the data based on whether the hybridization number was found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_known = dataQR.loc[dataQR.HYB_EXACT >= 0]\n",
    "d_unknown = dataQR.loc[dataQR.HYB_EXACT < 0]\n",
    "\n",
    "print(\"Finished instances: \", len(d_known), \"\\tUnfinished instances: \", len(d_unknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(d_known.HYB_EXACT, d_known.TIME_SEARCH, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide into datasets of different difficulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the datasets.\n",
    "d_easy = d_known.loc[d_known.TIME_SEARCH <= 10]\n",
    "d_medium = d_known.loc[d_known.TIME_SEARCH > 10]\n",
    "d_hard = d_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sizes.\\nEasy: \", len(d_easy), \"\\tMedium: \", len(d_medium), \"\\tHard: \", len(d_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the datasets into their own separate text files.\n",
    "def separate_datasets():\n",
    "    location = \"D:\\\\Uni\\\\DataInput\\\\\"\n",
    "\n",
    "    def save_file_names(d, name, location):\n",
    "        fName = location+name\n",
    "        f = open(fName, \"w+\")\n",
    "\n",
    "        for point in d:\n",
    "            f.write(point + \"\\n\")\n",
    "\n",
    "        f.close()\n",
    "\n",
    "    save_file_names(d_easy.ID.values, \"data_easy.txt\", location)\n",
    "    save_file_names(d_medium.ID.values, \"data_medium.txt\", location)\n",
    "    save_file_names(d_hard.ID.values, \"data_hard.txt\", location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the data from the run with basic TerminusEst (10min runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_files_with_text(text, path):\n",
    "    files = []\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if text in file:\n",
    "                files.append(os.path.join(r, file))\n",
    "    \n",
    "    return files\n",
    "\n",
    "def get_one_dataframe(files):\n",
    "    d = pd.read_csv(files[0])\n",
    "    for i in range(1, len(files)):\n",
    "        d = pd.concat([d, pd.read_csv(files[i])], axis=0, sort=False)\n",
    "    return d\n",
    "\n",
    "filesB = collect_files_with_text('basicTE', dataFolder)\n",
    "dataB = get_one_dataframe(filesB)\n",
    "dataB = remove_space_from_column_names(dataB)\n",
    "dataB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In java, I had to use -1 to mark data which was not registered. Correcting for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def set_lower_bound(x):\n",
    "    if (x.BASIC_HYB == -1 and math.isnan(x.BASIC_LB)):\n",
    "        print(\"ERROR! LB NOT LOGGED.\")\n",
    "    elif (not math.isnan(x.BASIC_LB)):\n",
    "        if (x.BASIC_LB <= 0):\n",
    "            print(\"ERROR!\")\n",
    "            print(x)\n",
    "            return -1\n",
    "        else:\n",
    "            return x.BASIC_LB\n",
    "    else:\n",
    "        return x.BASIC_HYB\n",
    "    \n",
    "dataB[\"LB_2\"] = dataB.apply(set_lower_bound, axis=1)\n",
    "dataB = dataB.sort_values(by=['ID']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_match(d1, d2, row_id):\n",
    "    if (len(d1.index) != len(d2.index)):\n",
    "        return false\n",
    "    \n",
    "    matches = d1[row_id] != d2[row_id]\n",
    "    return not matches.any()\n",
    "\n",
    "row_match(dataB, dataQR, 'ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the bounds for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = dataB[['ID', 'LB_2']]\n",
    "ub = dataQR[['ID', 'HYB_UPPER', 'TIME_BUILD_SEARCH_TREE']]\n",
    "bounds = pd.merge(lb, ub, on='ID')\n",
    "bounds = bounds.rename(columns={'LB_2':'LB', 'HYB_UPPER':'UB'})\n",
    "bounds['AR'] = bounds.UB / bounds.LB\n",
    "bounds['EXACT'] = bounds.LB == bounds.UB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds['DIFF'] = bounds.UB - bounds.LB\n",
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_easy = d_easy.ID.values\n",
    "id_medium = d_medium.ID.values\n",
    "id_hard = d_hard.ID.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get bounds data by difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_easy = bounds[bounds.ID.isin(id_easy)]\n",
    "bounds_medium = bounds[bounds.ID.isin(id_medium)]\n",
    "bounds_hard = bounds[bounds.ID.isin(id_hard)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Easy dataset AAS: \\n\", bounds_easy.mean(),\"\\n\\n\", bounds_easy.std())\n",
    "print(\"\\nMedium dataset AAS: \\n\", bounds_medium.mean(), \"\\n\\n\", bounds_medium.std())\n",
    "print(\"\\nHard dataset AAS: \\n\", bounds_hard.mean(), \"\\n\\n\", bounds_hard.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonexact(d):\n",
    "    temp = d[(d.UB-d.LB) >=1]\n",
    "    return (temp.UB - temp.LB)\n",
    "    \n",
    "\n",
    "sns.set(style='white')\n",
    "fig, ax =plt.subplots()\n",
    "ax = sns.distplot(nonexact(bounds_hard), kde=False, bins=5, axlabel=\"Difference\")\n",
    "ax.set_xticks([1,2,3,4,5])\n",
    "# ax.set_xticklabels([1,2,3,4,5])\n",
    "# ax.bar([1,2,3,4,5], 3, align='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenting parameter tuning info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_incomplete(d):\n",
    "    return d.loc[d.UPPER_BOUND != -1]\n",
    "\n",
    "def unknown_to_20(x):\n",
    "    if x.UPPER_BOUND == -1:\n",
    "        return 20\n",
    "    else:\n",
    "        return x.UPPER_BOUND\n",
    "\n",
    "def worst_case_incomplete(d):\n",
    "    return d.apply(lambda x: unknown_to_20(x), axis=1)\n",
    "\n",
    "# Parameter tuning data presentation.\n",
    "def present_param_tuning_info(name):\n",
    "    f = collect_files_with_text(name, dataFolder)\n",
    "    d = get_one_dataframe(f)\n",
    "    d = remove_space_from_column_names(d)\n",
    "    # d.UPPER_BOUND = worst_case_incomplete(d)\n",
    "    # d.DEPTH_FIRST_SOLUTION = worst_case_incomplete(d)\n",
    "    \n",
    "    # Get the lower bound for the relevant entries\n",
    "    lbs = bounds[bounds.ID.isin(d.ID)]\n",
    "    temp = pd.merge(d, lbs[['ID', 'LB']], on='ID')\n",
    "    d['AAR'] = temp.UPPER_BOUND / temp.LB\n",
    "    d['DIFF'] = temp.UPPER_BOUND - temp.LB\n",
    "    d['DIFF_FIRST'] = temp.DEPTH_FIRST_SOLUTION - temp.UPPER_BOUND\n",
    "    \n",
    "    return d\n",
    "    \n",
    "\n",
    "pt_hard = present_param_tuning_info(\"treeTE_hard_2_2\")\n",
    "pt_hard_c = remove_incomplete(pt_hard)\n",
    "subset = pt_hard[['AAR', 'DIFF', 'DIFF_FIRST', 'DEPTH_AVG', 'SHALLOWEST_LEAF', 'DEEPEST_NODE']]\n",
    "print(subset.mean())\n",
    "print(\"\\nIncomplete: \", len(pt_hard_c.index) / len(pt_hard.index))\n",
    "print(subset.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenting meta search info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def present_meta_search_info(name):\n",
    "    f = collect_files_with_text(name, dataFolder)\n",
    "    \n",
    "    points = []\n",
    "    for file in f:\n",
    "        d = pd.read_csv(file)\n",
    "        lbs = bounds[bounds.ID.isin(d.ID)]\n",
    "        temp = pd.merge(d, lbs[['ID', 'LB']], on='ID')\n",
    "        temp['DIFF'] = temp.UPPER_BOUND - temp.LB\n",
    "        if not 'T_COMPLETED' in temp.columns:\n",
    "            temp['T_COMPLETED'] = temp.trees[0]\n",
    "        points.append([temp.trees[0], temp.DIFF.mean(), (temp.trees > temp.T_COMPLETED).any()])\n",
    "    \n",
    "    return (points)\n",
    "\n",
    "\n",
    "l_meta1 = present_meta_search_info(\"metaTE_50k_hard\")\n",
    "l_meta1.sort()\n",
    "\n",
    "l_meta2 = present_meta_search_info(\"metaTE_hard\")\n",
    "l_meta2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_meta1 = pd.DataFrame(l_meta1)\n",
    "d_meta2 = pd.DataFrame(l_meta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d_meta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_meta1[0], d_meta1[1])\n",
    "plt.plot(d_meta2[0], d_meta2[1])\n",
    "plt.ylabel('Average Diff.')\n",
    "plt.xlabel('Number of runs')\n",
    "\n",
    "yellow = mpatches.Patch(color='orange', label=\"10'000 nodes\")\n",
    "blue = mpatches.Patch(color='tab:blue', label=\"50'000 nodes\")\n",
    "plt.legend(handles=[yellow, blue])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting information about hard dataset when run with TerminusEstMCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_hard = dataB[dataB.ID.isin(id_hard)]\n",
    "print(\"Avg. Diff: \", db_hard[db_hard.BASIC_HYB >= 0].BASIC_HYB.mean())\n",
    "print(\"Percent found: \", len(db_hard[db_hard.BASIC_HYB >= 0].index) / len(db_hard.index))\n",
    "print(\"AVg. time: \", dataB.BASIC_RUNTIME.mean())\n",
    "\n",
    "db_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_tem = collect_files_with_text(\"TE_MCTS\", dataFolder)\n",
    "f_tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tem = get_one_dataframe(f_tem)\n",
    "d_tem = remove_space_from_column_names(d_tem)\n",
    "d_tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_t = d_tem[['ID','TIME_TOTAL', 'CANCELED']].rename(columns={'TIME_TOTAL':'TIME_TEMCTS', 'CANCELED':'CANCELED_TEMCTS'})\n",
    "d_b = dataB[dataB.ID.isin(d_t.ID)][['ID', 'BASIC_RUNTIME', 'BASIC_HYB', 'LB_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_comp = pd.merge(d_t, d_b, on=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the TerminusEst and TerminusEstMCTS on the hard dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thing_1(x):\n",
    "    if x.CANCELED_TEMCTS == ' false':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def thing_2(x):\n",
    "    if x.BASIC_CANCELED:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "d_comp['BASIC_CANCELED'] = d_comp.BASIC_HYB == -1\n",
    "d_comp['TEMCTS_S'] = d_comp.apply(thing_1, axis=1)\n",
    "d_comp['BASIC_S'] = d_comp.apply(thing_2, axis=1)\n",
    "d_comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_comp[['TIME_TEMCTS', 'BASIC_RUNTIME', 'TEMCTS_S', 'BASIC_S']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting difference across LB found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "bounds.head()\n",
    "for name, group in bounds.groupby('UB'):\n",
    "    l.append([name, (group.EXACT.sum()/len(group.index)), len(group.index)])\n",
    "    \n",
    "pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds[bounds.UB - bounds.LB == 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
